# ğŸ¦œ LangChain Documentation Helper

<div align="center">

**An intelligent documentation assistant powered by LangChain and vector search**

<br>

[![Python](https://img.shields.io/badge/Python-ğŸ-blue.svg)](https://www.python.org/downloads/)
[![LangChain](https://img.shields.io/badge/LangChain-ğŸ¦œğŸ”—-green.svg)](https://langchain.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B.svg)](https://streamlit.io/)
[![Pinecone](https://img.shields.io/badge/Pinecone-ğŸŒ²-orange.svg)](https://pinecone.io/)
[![Tavily](https://img.shields.io/badge/Tavily-ğŸ”-purple.svg)](https://app.tavily.com/home?utm_campaign=eden_marco&utm_medium=socials&utm_source=linkedin)

</div>

## ğŸ¯ Overview

The **LangChain Documentation Helper** is a sophisticated AI-powered web application that serves as a slim version of [chat.langchain.com](https://chat.langchain.com/). This intelligent documentation assistant provides accurate answers to questions about LangChain documentation using advanced Retrieval-Augmented Generation (RAG) techniques, enhanced with web crawling capabilities and conversational memory.

### âœ¨ Key Features

**RAG Pipeline Flow:**

1. ğŸŒ **Web Crawling**: Real-time web scraping and content extraction using Tavily's advanced crawling capabilities
2. ğŸ“š **Document Processing**: Intelligent chunking and preprocessing of LangChain documentation
3. ğŸ” **Vector Storage**: Advanced embedding and indexing using Pinecone for fast similarity search
4. ğŸ¯ **Intelligent Retrieval**: Context-aware document retrieval based on user queries
5. ğŸ§© **Memory System**: Conversational memory for coreference resolution and context continuity
6. ğŸ§  **Context-Aware Generation**: Provides accurate, contextual answers with source citations
7. ğŸ’¬ **Interactive Interface**: User-friendly chat interface powered by Streamlit
8. ğŸš€ **Real-time Processing**: Fast end-to-end pipeline from query to response

## ğŸ¬ Demo

<div align="center">
  <img src="static/banner.gif" alt="Documentation Helper Demo" width="700">
  <p><em>Interactive demo showing the LangChain Documentation Helper in action</em></p>
</div>

## ğŸ› ï¸ Tech Stack

<div align="center">

| Component              | Technology            | Description                                     |
| ---------------------- | --------------------- | ----------------------------------------------- |
| ğŸ–¥ï¸ **Frontend**        | Streamlit             | Interactive web interface                       |
| ğŸ§  **AI Framework**    | LangChain ğŸ¦œğŸ”—        | Orchestrates the AI pipeline                    |
| ğŸ” **Vector Database** | Pinecone ğŸŒ²           | Stores and retrieves document embeddings        |
| ğŸŒ **Web Crawling**    | Tavily                | Intelligent web scraping and content extraction |
| ğŸ§© **Memory**          | Conversational Memory | Coreference resolution and context continuity   |
| ğŸ¤– **LLM**             | OpenAI GPT            | Powers the conversational AI                    |
| ğŸ **Backend**         | Python                | Core application logic                          |

</div>

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- OpenAI API key
- Pinecone API key
- [Tavily API key](https://app.tavily.com/home?utm_campaign=eden_marco&utm_medium=socials&utm_source=linkedin) (required - for documentation crawling and web search)

### Installation

2. **Set up environment variables**

   Create a `.env` file in the root directory:

   ```env
   PINECONE_API_KEY=your_pinecone_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   TAVILY_API_KEY=your_tavily_api_key_here  # Required - for documentation crawling
   ```

3. **Install dependencies**

   ```bash
   uv sync
   ```

4. **Ingest LangChain Documentation** (Run the ingestion pipeline)

   ```bash
   python ingestion.py  # Uses Tavily to crawl and index documentation
   ```

5. **Run the application**

   ```bash
   streamlit run main.py
   ```

6. **Open your browser** and navigate to `http://localhost:8501`

## ğŸ“ Project Structure

```
documentation-helper/
â”œâ”€â”€ backend/                          # Core backend logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ core.py
â”œâ”€â”€ static/                           # Static assets (images, logos)
â”‚   â”œâ”€â”€ banner.gif
â”‚   â”œâ”€â”€ LangChain Logo.png
â”‚   â””â”€â”€ Trimmed Padded Langchain.png
â”œâ”€â”€ chroma_db/                        # Local vector database
â”œâ”€â”€ main.py                           # Streamlit application entry point
â”œâ”€â”€ ingestion.py                      # Document ingestion pipeline
â”œâ”€â”€ consts.py                         # Configuration constants
â”œâ”€â”€ logger.py                         # Logging utilities
â”œâ”€â”€ Tavily Demo Tutorial.ipynb        # ğŸ“š Tutorial: Introduction to Tavily API
â”œâ”€â”€ Tavily Crawl Demo Tutorial.ipynb  # ğŸ“š Tutorial: Advanced Tavily crawling techniques
â””â”€â”€ requirements files                # pyproject.toml
```

### ğŸ“š Tutorial Notebooks

The project includes comprehensive Jupyter notebooks that serve as hands-on tutorials:

- **`Tavily Demo Tutorial.ipynb`**: Introduction to Tavily API basics and core functionality
- **`Tavily Crawl Demo Tutorial.ipynb`**: Advanced tutorial covering Tavily's crawling capabilities, including TavilyMap and TavilyExtract features

## ğŸ“š Learning Resources

This project is designed as a learning tool for understanding:

- ğŸ¦œ LangChain framework implementation
- ğŸ” Vector search and embeddings
- ğŸ’¬ Conversational AI development
- ğŸ—ï¸ RAG (Retrieval-Augmented Generation) architecture
